{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"dd-vault-ingest \u00b6 Service that processes deposits converting them to RDA compliant bags and sends them to the vault. SYNOPSIS \u00b6 dd-vault-ingest { server | check } DESCRIPTION \u00b6 This service is part of the DANS Vault Service. It is responsible for processing deposits, converting them to RDA compliant bags and sending them to the DANS Data Vault. This service resembles dd-ingest-flow in that it processes deposits and that these deposits eventually end up in the Vault. However, this service differs from dd-ingest-flow in that it does not create a Dataverse dataset version for each deposit, relying on Dataverse to automatically export the dataset version to and RDA compliant bag. Instead, this service creates the RDA compliant bag directly from the deposit. That said, the resulting bag is still designed to closely resemble the Dataverse bag. Ingest areas \u00b6 An ingest area is a directory on local disk storage that is used by the service to receive deposits. It contains the following subdirectories: inbox - the directory under which all input deposits must be located outbox - a directory where the processed deposit are moved to (if successful to a subdirectory processed , otherwise to one of rejected or failed ) The service currently supports only one ingest area: auto-ingest - for continuous import of deposits offered through deposit service, such as dd-sword2 . Processing of a deposit \u00b6 Order of deposit processing \u00b6 A deposit directory represents one dataset version. The version history of a datasets is represented by a sequence of deposit directories. When enqueuing deposits the program will first order them by the timestamp in the Created element in the contained bag's bag-info.txt file. Processing steps \u00b6 The processing of a deposit consists of the following steps: Basic scenario \u00b6 Check that the deposit is a valid deposit directory . Check that the bag in the deposit is a valid v1 DANS bag . Generate an NBN persistent identifier for the dataset and use that for the dansNbn field in the vault metadata. Create a new, zipped RDA compliant bag from the deposit. Register the bag in the dd-vault-catalog with minimal metadata: bag ID, NBN, and swordToken. Move the deposit to the outbox/processed directory and change its state to RECEIVED . Update scenario \u00b6 2a Part of the validation will be to check that the deposit is an update to an existing dataset by checking that the Is-Version-Of field in the bag-info.txt file of the deposit matches the swordToken of a dataset in the vault catalog. 3a Instead of generating a new NBN, the Vault Catalog will be queried for the NBN of the dataset that is being updated. ARGUMENTS \u00b6 positional arguments: {server,check} available commands named arguments: -h, --help show this help message and exit -v, --version show the application version and exit INSTALLATION AND CONFIGURATION \u00b6 Currently, this project is built as an RPM package for RHEL7/CentOS7 and later. The RPM will install the binaries to /opt/dans.knaw.nl/dd-vault-ingest and the configuration files to /etc/opt/dans.knaw.nl/dd-vault-ingest . For installation on systems that do no support RPM and/or systemd: Build the tarball (see next section). Extract it to some location on your system, for example /opt/dans.knaw.nl/dd-vault-ingest . Start the service with the following command /opt/dans.knaw.nl/dd-vault-ingest/bin/dd-vault-ingest server /opt/dans.knaw.nl/dd-vault-ingest/cfg/config.yml BUILDING FROM SOURCE \u00b6 Prerequisites: Java 11 or higher Maven 3.3.3 or higher RPM Steps: git clone https://github.com/DANS-KNAW/dd-vault-ingest.git cd dd-vault-ingest mvn clean install If the rpm executable is found at /usr/local/bin/rpm , the build profile that includes the RPM packaging will be activated. If rpm is available, but at a different path, then activate it by using Maven's -P switch: mvn -Pprm install . Alternatively, to build the tarball execute: mvn clean install assembly:single","title":"Manual"},{"location":"#dd-vault-ingest","text":"Service that processes deposits converting them to RDA compliant bags and sends them to the vault.","title":"dd-vault-ingest"},{"location":"#synopsis","text":"dd-vault-ingest { server | check }","title":"SYNOPSIS"},{"location":"#description","text":"This service is part of the DANS Vault Service. It is responsible for processing deposits, converting them to RDA compliant bags and sending them to the DANS Data Vault. This service resembles dd-ingest-flow in that it processes deposits and that these deposits eventually end up in the Vault. However, this service differs from dd-ingest-flow in that it does not create a Dataverse dataset version for each deposit, relying on Dataverse to automatically export the dataset version to and RDA compliant bag. Instead, this service creates the RDA compliant bag directly from the deposit. That said, the resulting bag is still designed to closely resemble the Dataverse bag.","title":"DESCRIPTION"},{"location":"#ingest-areas","text":"An ingest area is a directory on local disk storage that is used by the service to receive deposits. It contains the following subdirectories: inbox - the directory under which all input deposits must be located outbox - a directory where the processed deposit are moved to (if successful to a subdirectory processed , otherwise to one of rejected or failed ) The service currently supports only one ingest area: auto-ingest - for continuous import of deposits offered through deposit service, such as dd-sword2 .","title":"Ingest areas"},{"location":"#processing-of-a-deposit","text":"","title":"Processing of a deposit"},{"location":"#order-of-deposit-processing","text":"A deposit directory represents one dataset version. The version history of a datasets is represented by a sequence of deposit directories. When enqueuing deposits the program will first order them by the timestamp in the Created element in the contained bag's bag-info.txt file.","title":"Order of deposit processing"},{"location":"#processing-steps","text":"The processing of a deposit consists of the following steps:","title":"Processing steps"},{"location":"#basic-scenario","text":"Check that the deposit is a valid deposit directory . Check that the bag in the deposit is a valid v1 DANS bag . Generate an NBN persistent identifier for the dataset and use that for the dansNbn field in the vault metadata. Create a new, zipped RDA compliant bag from the deposit. Register the bag in the dd-vault-catalog with minimal metadata: bag ID, NBN, and swordToken. Move the deposit to the outbox/processed directory and change its state to RECEIVED .","title":"Basic scenario"},{"location":"#update-scenario","text":"2a Part of the validation will be to check that the deposit is an update to an existing dataset by checking that the Is-Version-Of field in the bag-info.txt file of the deposit matches the swordToken of a dataset in the vault catalog. 3a Instead of generating a new NBN, the Vault Catalog will be queried for the NBN of the dataset that is being updated.","title":"Update scenario"},{"location":"#arguments","text":"positional arguments: {server,check} available commands named arguments: -h, --help show this help message and exit -v, --version show the application version and exit","title":"ARGUMENTS"},{"location":"#installation-and-configuration","text":"Currently, this project is built as an RPM package for RHEL7/CentOS7 and later. The RPM will install the binaries to /opt/dans.knaw.nl/dd-vault-ingest and the configuration files to /etc/opt/dans.knaw.nl/dd-vault-ingest . For installation on systems that do no support RPM and/or systemd: Build the tarball (see next section). Extract it to some location on your system, for example /opt/dans.knaw.nl/dd-vault-ingest . Start the service with the following command /opt/dans.knaw.nl/dd-vault-ingest/bin/dd-vault-ingest server /opt/dans.knaw.nl/dd-vault-ingest/cfg/config.yml","title":"INSTALLATION AND CONFIGURATION"},{"location":"#building-from-source","text":"Prerequisites: Java 11 or higher Maven 3.3.3 or higher RPM Steps: git clone https://github.com/DANS-KNAW/dd-vault-ingest.git cd dd-vault-ingest mvn clean install If the rpm executable is found at /usr/local/bin/rpm , the build profile that includes the RPM packaging will be activated. If rpm is available, but at a different path, then activate it by using Maven's -P switch: mvn -Pprm install . Alternatively, to build the tarball execute: mvn clean install assembly:single","title":"BUILDING FROM SOURCE"},{"location":"arch/","text":"DANS Data Station Architecture \u00b6 This module is a component in the DANS Data Station Architecture .","title":"\u21d2 DANS Data Station Architecture"},{"location":"arch/#dans-data-station-architecture","text":"This module is a component in the DANS Data Station Architecture .","title":"DANS Data Station Architecture"},{"location":"dev/","text":"Development \u00b6 This page contains information for developers about how to contribute to this project. Set-up \u00b6 This project can be used in combination with dans-dev-tools . Before you can start it as a service some dependencies must first be started. One dependency is dd-validate-dans-bag . For the other dependency you have the choice between a local service dd-vault-catalog and a Virtual Machine (VM) dev_transfer . The local variant requires a local database. For the VM you need access to the project dd-dtap , Initialize development environment \u00b6 This is only necessary once per project. If you execute this any existing configuration and data will be reset. Open separate terminal tabs for dd-vault-ingest , its dependency dd-validate-dans-bag and the optional dependency (when not using the VM dev_transfer ) dd-vault-catalog . In each tab run: start-env.sh The service dd-validate-dans-bag needs different configurations for dd-vault-ingest and other services. So you will have to update the generated dd-validate-dans-bag/etc/config.yml , perhaps keep copies of the files or comment lines to switch between both situations. dataverse: null vaultCatalog.baseUrl: https://dev.transfer.dans-data.nl/vault-catalog You will also have to adjust dd-vault-ingest/etc/config.yml : vaultCatalog.url: https://dev.transfer.dans-data.nl Both URLs in the above configuration examples assume you use the VM dev_transfer , if not, keep the URLs as generated from src/test/resources/debug-etc . Start services \u00b6 To start the VM, run in the root of dd-dtap : start-preprovisioned-box.py -s dev_transfer Without the VM you will need a local database for the service dd-vault-catalog , run in a separate terminal tab: start-hsqldb-server.sh Pick the appropriate vaultCatalog.url in dd-vault-ingest/etc/config.yml . Open terminal tabs for the services dd-vault-ingest , dd-validate-dans-bag , optionally (when not using the VM dev_transfer ) dd-vault-catalog and run in each: start-service.sh Create a deposit \u00b6 Create a directory /vagrant/shared/<UUID> , this location makes it available on VMs at /vagrant/shared . Copy a valid bag into that directory, for example: dd-dans-sword2-examples/src/main/resources/example-bags/valid/default-open Note that all_mappings has an invalid prefix for Has-Organizational-Identifier in bag-info.txt . Create a file in the same directory named deposit.properties , an example for the content: bag-store.bag-id = <UUID> dataverse.bag-id = urn:uuid:<UUID> dataverse.sword-token = sword:<UUID> creation.timestamp = 2023-08-16T17:40:41.390209+02:00 deposit.origin = SWORD2 depositor.userId = user001 bag-store.bag-name = default-open Note that * The bag-name should match the copied bag. * The userId should match a value configured as a dataSupplier in dd-vault-ingest/etc/config.yml . * The <UUID> should match the directory name. * To test updates you will need different UUIDs for each example-bags/valid/* and move them to the inbox. Note that the revision02 and revision03 bags lack an Is-Version-Of: <UUID> in bag-info.txt , it must be a valid SWORD token in the vault catalog. Adding this property requires an update of the tagmanifest-sha1.txt . A validation error message will show the proper value, for example (with a locally running validator): cd dd-dans-sword2-examples ./run-validation.sh http://localhost:20330/validate /vagrant/shared/ / Start an ingest \u00b6 To start an ingest locally, move (not copy, otherwise the processing might start before the copy completed) a deposit into one of the inboxes configured in: dd-vault-ingest/etc/config.yml You can examine details of the result on dev_transfer in /var/opt/dans.knaw.nl/tmp/ocfl-tar/inbox and the database: sudo su postgres psql dd_vault_catalog select bag_id, data_supplier from ocfl_object_versions; \\c dd_transfer_to_vault select bag_id, data_supplier from transfer_item; Or examine the local transfer results in dd-vault-ingest/data/rda-bags and with start-hsqldb-client.sh executed in dd-vault-catalog . The start dialog needs database.url specified in dd-vault-catalog/etc/config.yml . Test after deploy \u00b6 The catalog results can be found on the VM dev_transfer , the service under test ( dd-vault-ingest ) should be deployed on dev_vaas , both VMs should be running. Make the deposits available that were prepared in /vagrant/shared : cd /var/opt/dans.knaw.nl/tmp/auto-ingest # configured in /etc/opt/dans.knaw.nl/dd-vault-ingest/config.ym cp -r `readlink -m /vagrant/shared/*/revision*/..` .. # or the actually wrapped bag(s) chmod -R 777 ../*7* Start an ingest: mv -v `readlink -m ../*/revision01/..` inbox Or see dd-dans-sword2-examples with IRI https://dev.sword2.vaas.datastations.nl/collection/1","title":"Development"},{"location":"dev/#development","text":"This page contains information for developers about how to contribute to this project.","title":"Development"},{"location":"dev/#set-up","text":"This project can be used in combination with dans-dev-tools . Before you can start it as a service some dependencies must first be started. One dependency is dd-validate-dans-bag . For the other dependency you have the choice between a local service dd-vault-catalog and a Virtual Machine (VM) dev_transfer . The local variant requires a local database. For the VM you need access to the project dd-dtap ,","title":"Set-up"},{"location":"dev/#initialize-development-environment","text":"This is only necessary once per project. If you execute this any existing configuration and data will be reset. Open separate terminal tabs for dd-vault-ingest , its dependency dd-validate-dans-bag and the optional dependency (when not using the VM dev_transfer ) dd-vault-catalog . In each tab run: start-env.sh The service dd-validate-dans-bag needs different configurations for dd-vault-ingest and other services. So you will have to update the generated dd-validate-dans-bag/etc/config.yml , perhaps keep copies of the files or comment lines to switch between both situations. dataverse: null vaultCatalog.baseUrl: https://dev.transfer.dans-data.nl/vault-catalog You will also have to adjust dd-vault-ingest/etc/config.yml : vaultCatalog.url: https://dev.transfer.dans-data.nl Both URLs in the above configuration examples assume you use the VM dev_transfer , if not, keep the URLs as generated from src/test/resources/debug-etc .","title":"Initialize development environment"},{"location":"dev/#start-services","text":"To start the VM, run in the root of dd-dtap : start-preprovisioned-box.py -s dev_transfer Without the VM you will need a local database for the service dd-vault-catalog , run in a separate terminal tab: start-hsqldb-server.sh Pick the appropriate vaultCatalog.url in dd-vault-ingest/etc/config.yml . Open terminal tabs for the services dd-vault-ingest , dd-validate-dans-bag , optionally (when not using the VM dev_transfer ) dd-vault-catalog and run in each: start-service.sh","title":"Start services"},{"location":"dev/#create-a-deposit","text":"Create a directory /vagrant/shared/<UUID> , this location makes it available on VMs at /vagrant/shared . Copy a valid bag into that directory, for example: dd-dans-sword2-examples/src/main/resources/example-bags/valid/default-open Note that all_mappings has an invalid prefix for Has-Organizational-Identifier in bag-info.txt . Create a file in the same directory named deposit.properties , an example for the content: bag-store.bag-id = <UUID> dataverse.bag-id = urn:uuid:<UUID> dataverse.sword-token = sword:<UUID> creation.timestamp = 2023-08-16T17:40:41.390209+02:00 deposit.origin = SWORD2 depositor.userId = user001 bag-store.bag-name = default-open Note that * The bag-name should match the copied bag. * The userId should match a value configured as a dataSupplier in dd-vault-ingest/etc/config.yml . * The <UUID> should match the directory name. * To test updates you will need different UUIDs for each example-bags/valid/* and move them to the inbox. Note that the revision02 and revision03 bags lack an Is-Version-Of: <UUID> in bag-info.txt , it must be a valid SWORD token in the vault catalog. Adding this property requires an update of the tagmanifest-sha1.txt . A validation error message will show the proper value, for example (with a locally running validator): cd dd-dans-sword2-examples ./run-validation.sh http://localhost:20330/validate /vagrant/shared/ /","title":"Create a deposit"},{"location":"dev/#start-an-ingest","text":"To start an ingest locally, move (not copy, otherwise the processing might start before the copy completed) a deposit into one of the inboxes configured in: dd-vault-ingest/etc/config.yml You can examine details of the result on dev_transfer in /var/opt/dans.knaw.nl/tmp/ocfl-tar/inbox and the database: sudo su postgres psql dd_vault_catalog select bag_id, data_supplier from ocfl_object_versions; \\c dd_transfer_to_vault select bag_id, data_supplier from transfer_item; Or examine the local transfer results in dd-vault-ingest/data/rda-bags and with start-hsqldb-client.sh executed in dd-vault-catalog . The start dialog needs database.url specified in dd-vault-catalog/etc/config.yml .","title":"Start an ingest"},{"location":"dev/#test-after-deploy","text":"The catalog results can be found on the VM dev_transfer , the service under test ( dd-vault-ingest ) should be deployed on dev_vaas , both VMs should be running. Make the deposits available that were prepared in /vagrant/shared : cd /var/opt/dans.knaw.nl/tmp/auto-ingest # configured in /etc/opt/dans.knaw.nl/dd-vault-ingest/config.ym cp -r `readlink -m /vagrant/shared/*/revision*/..` .. # or the actually wrapped bag(s) chmod -R 777 ../*7* Start an ingest: mv -v `readlink -m ../*/revision01/..` inbox Or see dd-dans-sword2-examples with IRI https://dev.sword2.vaas.datastations.nl/collection/1","title":"Test after deploy"}]}